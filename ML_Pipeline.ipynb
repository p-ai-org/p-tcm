{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb0a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c43bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/data_processed.csv', index_col=0)\n",
    "df = pd.read_csv('./data/data_processed_normalized.csv', index_col=0)\n",
    "# df = pd.read_csv('./data/raw_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e49dbc7",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(df, y_col_name):\n",
    "    \"\"\"\n",
    "    Apply sample logistic regression model to dataframe\n",
    "\n",
    "    df : (dataframe)\n",
    "    x : (compounds column as int)\n",
    "    y : (classification column as int)\n",
    "    \"\"\"\n",
    "    # values of each column\n",
    "    x = df.iloc[:, 1:] # df.iloc[2:, 1:39]??\n",
    "    y = df[y_col_name][:]\n",
    "\n",
    "    # split data into training and test set\n",
    "    # 75 training, 25 testing\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    train = data_process(pd.concat([xtrain, ytrain]))\n",
    "    xtrain = trian.iloc[:, 1:39]\n",
    "    ytrain = train[y_col_name][:]\n",
    "    \n",
    "    test = data_process(pd.concat([xtest, ytest], axis=1))\n",
    "    xtest = test.iloc[:, 1:39]\n",
    "    ytest = test[y_col_name][:]\n",
    "\n",
    "\n",
    "    # standardize and scale data\n",
    "    scaler = StandardScaler()\n",
    "    xtrain = scaler.fit_transform(xtrain)\n",
    "    xtest = scaler.transform(xtest)\n",
    "\n",
    "    # modeling + analysis\n",
    "    model = LogisticRegression(random_state=0)\n",
    "    model.fit(xtrain, ytrain.ravel())\n",
    "    y_pred = model.predict(xtest)\n",
    "\n",
    "    # confusion matrix of test size\n",
    "    conf_m = confusion_matrix(ytest, y_pred)\n",
    "    print(\"Confusion Matrix : \", conf_m)\n",
    "\n",
    "    # accuracy score of test size\n",
    "    print (\"Accuracy : \", accuracy_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression(df, \"hot_cold_scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc966dc",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(df, y_col_name):\n",
    "    x = df.iloc[:, 1:39]\n",
    "    y = df[y_col_name][:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    print (\"Accuracy : \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77dfca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(df, \"hot_cold_scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec43447",
   "metadata": {},
   "source": [
    "more processing for following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0330ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_mode(row):\n",
    "    if row['Mode'] == 'Plain':\n",
    "        return 0\n",
    "    elif row['Mode'] == 'Cold':\n",
    "        return 1\n",
    "    elif row['Mode'] == 'Hot':\n",
    "        return 2\n",
    "    \n",
    "df['mode_code'] = df.apply (lambda row: label_mode(row), axis=1)\n",
    "df = df.drop(columns='Food Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a86d51",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495829a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(df):\n",
    "    X = df.drop([\"Plain Occurences\", \"Cool Occurences\", \"Warm Occurences\", \"Cold Occurences\", \"Heavy Cold Occurences\", \"Heavy Warm Occurences\",\"Hot Occurences\", \"Heavy Hot Occurences\", \"mode_code\", \"Mode\"], axis = 1)\n",
    "    Y = df[\"mode_code\"].astype('int')\n",
    "    factor = pd.factorize(df['Mode'])\n",
    "    df.Mode = factor[0]\n",
    "    definitions = factor[1]\n",
    "    print(definitions)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 21)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    reversefactor = dict(zip(range(3),definitions))\n",
    "    y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "    y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "    print(pd.crosstab(y_test, y_pred, rownames=['Actual Temp'], colnames=['Predicted Temp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65be827",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_forest(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd6ae67",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(df):\n",
    "    X = df.drop([\"Plain Occurences\", \"Cool Occurences\", \"Warm Occurences\", \"Cold Occurences\", \"Heavy Cold Occurences\", \"Heavy Warm Occurences\",\"Hot Occurences\", \"Heavy Hot Occurences\", \"mode_code\", \"Mode\"], axis = 1)\n",
    "    y = df[\"mode_code\"]\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.80, test_size=0.20, random_state=101)\n",
    "    rbf = SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train, y_train)\n",
    "    poly = SVC(kernel='poly', degree=3, C=1).fit(X_train, y_train)\n",
    "    poly_pred = poly.predict(X_test)\n",
    "    rbf_pred = rbf.predict(X_test)\n",
    "    poly_accuracy = accuracy_score(y_test, poly_pred)\n",
    "    poly_f1 = f1_score(y_test, poly_pred, average='weighted')\n",
    "    print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))\n",
    "    print('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1*100))\n",
    "    rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
    "    rbf_f1 = f1_score(y_test, rbf_pred, average='weighted')\n",
    "    print('Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\n",
    "    print('F1 (RBF Kernel): ', \"%.2f\" % (rbf_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742fdf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e8abd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
