{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb0a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46c43bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/data_processed.csv', index_col=0)\n",
    "df = pd.read_csv('./data/data_processed_normalized.csv', index_col=0)\n",
    "# df = pd.read_csv('./data/raw_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c99b43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Water (g)', 'Energy (kal)', 'Protein (g)', 'lipid (g)',\n",
       "       'Carbohydrate (g)', 'Fiber (g)', 'Ash (g)', 'Ca (mg)', 'Fe (mg)',\n",
       "       'Mg (mg)', 'P (mg)', 'K (mg)', 'Na (mg)', 'Zn (mg)', 'Se (µg)',\n",
       "       'Cu (mg)', 'Mn (mg)', 'Vc (mg)', 'Thiamin (mg)', 'Riboflavin (mg)',\n",
       "       'Niacin (mg)', 'B6 (mg)', 'Folate,DFE (µg)', 'B12 (µg)', 'Va,RAE (µg)',\n",
       "       'Ve (mg)', 'saturated (g)', 'monounsaturated (g)',\n",
       "       'polyunsaturated (g)', 'trans (g)', 'Cholesterol (mg)', 'Caffeine (mg)',\n",
       "       'phenolics (mg)', 'pH', 'Plain Occurences', 'Cool Occurences',\n",
       "       'Warm Occurences', 'Cold Occurences', 'Heavy Cold Occurences',\n",
       "       'Heavy Warm Occurences', 'Hot Occurences', 'Heavy Hot Occurences',\n",
       "       '% Plain', '% Cool', '% Warm', '% Cold', '% Heavy Cold', '% Heavy Warm',\n",
       "       '% Hot', '% Heavy Hot', 'hot_cold_scale', 'Plain', 'Cold', 'Hot',\n",
       "       'Mode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "105aa38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['% Plain', '% Cool', '% Warm', '% Cold', '% Heavy Cold', '% Heavy Warm',\n",
    "       '% Hot', '% Heavy Hot', 'Plain', 'Cold', 'Hot','Mode', 'Plain Occurences', 'Cool Occurences',\n",
    "       'Warm Occurences', 'Cold Occurences', 'Heavy Cold Occurences',\n",
    "       'Heavy Warm Occurences', 'Hot Occurences', 'Heavy Hot Occurences',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b168f7d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Water (g)', 'Energy (kal)', 'Protein (g)', 'lipid (g)',\n",
       "       'Carbohydrate (g)', 'Fiber (g)', 'Ash (g)', 'Ca (mg)', 'Fe (mg)',\n",
       "       'Mg (mg)', 'P (mg)', 'K (mg)', 'Na (mg)', 'Zn (mg)', 'Se (µg)',\n",
       "       'Cu (mg)', 'Mn (mg)', 'Vc (mg)', 'Thiamin (mg)', 'Riboflavin (mg)',\n",
       "       'Niacin (mg)', 'B6 (mg)', 'Folate,DFE (µg)', 'B12 (µg)', 'Va,RAE (µg)',\n",
       "       'Ve (mg)', 'saturated (g)', 'monounsaturated (g)',\n",
       "       'polyunsaturated (g)', 'trans (g)', 'Cholesterol (mg)', 'Caffeine (mg)',\n",
       "       'phenolics (mg)', 'pH', 'hot_cold_scale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc5eb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Water (g)</th>\n",
       "      <th>Energy (kal)</th>\n",
       "      <th>Protein (g)</th>\n",
       "      <th>lipid (g)</th>\n",
       "      <th>Carbohydrate (g)</th>\n",
       "      <th>Fiber (g)</th>\n",
       "      <th>Ash (g)</th>\n",
       "      <th>Ca (mg)</th>\n",
       "      <th>Fe (mg)</th>\n",
       "      <th>...</th>\n",
       "      <th>% Cold</th>\n",
       "      <th>% Heavy Cold</th>\n",
       "      <th>% Heavy Warm</th>\n",
       "      <th>% Hot</th>\n",
       "      <th>% Heavy Hot</th>\n",
       "      <th>hot_cold_scale</th>\n",
       "      <th>Plain</th>\n",
       "      <th>Cold</th>\n",
       "      <th>Hot</th>\n",
       "      <th>Mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfalfa</td>\n",
       "      <td>0.903084</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.092251</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.029565</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.093645</td>\n",
       "      <td>0.028747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dolichos sinensis</td>\n",
       "      <td>0.902082</td>\n",
       "      <td>0.020362</td>\n",
       "      <td>0.040590</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.074421</td>\n",
       "      <td>0.080827</td>\n",
       "      <td>0.007014</td>\n",
       "      <td>0.051839</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hazelnuts</td>\n",
       "      <td>0.053164</td>\n",
       "      <td>0.710407</td>\n",
       "      <td>0.275830</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>0.170252</td>\n",
       "      <td>0.182331</td>\n",
       "      <td>0.041082</td>\n",
       "      <td>0.095318</td>\n",
       "      <td>0.048255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beans, kidney</td>\n",
       "      <td>0.117641</td>\n",
       "      <td>0.376697</td>\n",
       "      <td>0.435055</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.611785</td>\n",
       "      <td>0.468045</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peanuts,</td>\n",
       "      <td>0.065078</td>\n",
       "      <td>0.641403</td>\n",
       "      <td>0.476015</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.164441</td>\n",
       "      <td>0.159774</td>\n",
       "      <td>0.032064</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.047023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Plain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.1  Water (g)  Energy (kal)  Protein (g)  lipid (g)  \\\n",
       "0            Alfalfa   0.903084      0.036199     0.092251     0.0070   \n",
       "1  dolichos sinensis   0.902082      0.020362     0.040590     0.0030   \n",
       "2          hazelnuts   0.053164      0.710407     0.275830     0.6075   \n",
       "3      Beans, kidney   0.117641      0.376697     0.435055     0.0083   \n",
       "4           Peanuts,   0.065078      0.641403     0.476015     0.4924   \n",
       "\n",
       "   Carbohydrate (g)  Fiber (g)   Ash (g)   Ca (mg)   Fe (mg)  ...  % Cold  \\\n",
       "0          0.029565   0.035714  0.012024  0.093645  0.028747  ...     0.0   \n",
       "1          0.074421   0.080827  0.007014  0.051839  0.008214  ...     0.0   \n",
       "2          0.170252   0.182331  0.041082  0.095318  0.048255  ...     0.0   \n",
       "3          0.611785   0.468045  0.009018  0.119565  0.084189  ...     0.0   \n",
       "4          0.164441   0.159774  0.032064  0.076923  0.047023  ...     0.0   \n",
       "\n",
       "   % Heavy Cold  % Heavy Warm  % Hot  % Heavy Hot  hot_cold_scale  Plain  \\\n",
       "0           0.0           0.0    0.0          0.0              10      3   \n",
       "1           0.0           0.0    0.0          0.0              10      3   \n",
       "2           0.0           0.0    0.0          0.0              10      3   \n",
       "3           0.0           0.0    0.0          0.0              10      3   \n",
       "4           0.0           0.0    0.0          0.0              10      3   \n",
       "\n",
       "   Cold  Hot   Mode  \n",
       "0     0    0  Plain  \n",
       "1     0    0  Plain  \n",
       "2     0    0  Plain  \n",
       "3     0    0  Plain  \n",
       "4     0    0  Plain  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e49dbc7",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "235e522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(df, y_col_name):\n",
    "    \"\"\"\n",
    "    Apply sample logistic regression model to dataframe\n",
    "\n",
    "    df : (dataframe)\n",
    "    x : (compounds column as int)\n",
    "    y : (classification column as int)\n",
    "    \"\"\"\n",
    "    # values of each column\n",
    "    x = df.iloc[:, 1:-1] # df.iloc[2:, 1:39]??\n",
    "    y = df[y_col_name][:]\n",
    "\n",
    "    # split data into training and test set\n",
    "    # 75 training, 25 testing\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "    # standardize and scale data\n",
    "    scaler = StandardScaler()\n",
    "    xtrain = scaler.fit_transform(xtrain)\n",
    "    xtest = scaler.transform(xtest)\n",
    "\n",
    "    # modeling + analysis\n",
    "    model = LogisticRegression(random_state=0)\n",
    "    model.fit(xtrain, ytrain.ravel())\n",
    "    y_pred = model.predict(xtest)\n",
    "\n",
    "    # confusion matrix of test size\n",
    "    conf_m = confusion_matrix(ytest, y_pred)\n",
    "    print(\"Confusion Matrix : \", conf_m)\n",
    "\n",
    "    # accuracy score of test size\n",
    "    print (\"Accuracy : \", accuracy_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f2d9bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :  [[0 0 0 0 1 0 0 0 0 0 2 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 4 0 0]\n",
      " [0 0 1 1 2 1 0 0 0 0 3 0 0]\n",
      " [0 0 1 0 1 0 0 1 0 0 2 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 6 0 0 1 1 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0]]\n",
      "Accuracy :  0.1836734693877551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronxie/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(df, \"hot_cold_scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc966dc",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77b2174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(df, y_col_name):\n",
    "    x = df.iloc[:, 1:-1] # df.iloc[2:, 1:39]??\n",
    "    y = df[y_col_name][:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    print (\"Accuracy : \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c77dfca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.16326530612244897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronxie/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "knn(df, \"hot_cold_scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec43447",
   "metadata": {},
   "source": [
    "more processing for following"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a86d51",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a4367fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Water (g)', 'Energy (kal)', 'Protein (g)', 'lipid (g)',\n",
       "       'Carbohydrate (g)', 'Fiber (g)', 'Ash (g)', 'Ca (mg)', 'Fe (mg)',\n",
       "       'Mg (mg)', 'P (mg)', 'K (mg)', 'Na (mg)', 'Zn (mg)', 'Se (µg)',\n",
       "       'Cu (mg)', 'Mn (mg)', 'Vc (mg)', 'Thiamin (mg)', 'Riboflavin (mg)',\n",
       "       'Niacin (mg)', 'B6 (mg)', 'Folate,DFE (µg)', 'B12 (µg)', 'Va,RAE (µg)',\n",
       "       'Ve (mg)', 'saturated (g)', 'monounsaturated (g)',\n",
       "       'polyunsaturated (g)', 'trans (g)', 'Cholesterol (mg)', 'Caffeine (mg)',\n",
       "       'phenolics (mg)', 'pH', 'Plain Occurences', 'Cool Occurences',\n",
       "       'Warm Occurences', 'Cold Occurences', 'Heavy Cold Occurences',\n",
       "       'Heavy Warm Occurences', 'Hot Occurences', 'Heavy Hot Occurences',\n",
       "       '% Plain', '% Cool', '% Warm', '% Cold', '% Heavy Cold', '% Heavy Warm',\n",
       "       '% Hot', '% Heavy Hot', 'hot_cold_scale', 'Plain', 'Cold', 'Hot',\n",
       "       'Mode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/data_processed_normalized.csv', index_col=0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e0330ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_mode(row):\n",
    "    if row['Mode'] == 'Plain':\n",
    "        return 0\n",
    "    elif row['Mode'] == 'Cold':\n",
    "        return 1\n",
    "    elif row['Mode'] == 'Hot':\n",
    "        return 2\n",
    "    \n",
    "df['mode_code'] = df.apply (lambda row: label_mode(row), axis=1)\n",
    "df = df.drop(columns='Unnamed: 0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cdccee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "236    2\n",
       "237    2\n",
       "238    2\n",
       "239    2\n",
       "240    2\n",
       "Name: mode_code, Length: 241, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mode_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "495829a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(df):\n",
    "    X = df.drop([\"Plain Occurences\", \"Cool Occurences\", \"Warm Occurences\", \"Cold Occurences\", \"Heavy Cold Occurences\", \"Heavy Warm Occurences\",\"Hot Occurences\", \"Heavy Hot Occurences\", \"mode_code\", \"Mode\", '% Plain', '% Cool', '% Warm', '% Cold', '% Heavy Cold', '% Heavy Warm','% Hot', '% Heavy Hot', 'Plain', 'Cold', 'Hot', 'hot_cold_scale'], axis = 1)\n",
    "    Y = df[\"mode_code\"].astype('int')\n",
    "\n",
    "    factor = pd.factorize(df['Mode'])\n",
    "    df.Mode = factor[0]\n",
    "    definitions = factor[1]\n",
    "    print(definitions)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 21)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    reversefactor = dict(zip(range(3),definitions))\n",
    "    y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "    y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "    print(pd.crosstab(y_test, y_pred, rownames=['Actual Temp'], colnames=['Predicted Temp']))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f65be827",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2], dtype='int64')\n",
      "Predicted Temp   0   1  2\n",
      "Actual Temp              \n",
      "0               14   4  3\n",
      "1                9  15  1\n",
      "2                6   4  5\n",
      "0.5573770491803278\n"
     ]
    }
   ],
   "source": [
    "random_forest(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd6ae67",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e4c7906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(df):\n",
    "    X = df.drop([\"Plain Occurences\", \"Cool Occurences\", \"Warm Occurences\", \"Cold Occurences\", \"Heavy Cold Occurences\", \"Heavy Warm Occurences\",\"Hot Occurences\", \"Heavy Hot Occurences\", \"mode_code\", \"Mode\", '% Plain', '% Cool', '% Warm', '% Cold', '% Heavy Cold', '% Heavy Warm','% Hot', '% Heavy Hot', 'Plain', 'Cold', 'Hot', 'hot_cold_scale'], axis = 1)\n",
    "    y = df[\"mode_code\"].astype('int')\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.80, test_size=0.20, random_state=101)\n",
    "    rbf = SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train, y_train)\n",
    "    poly = SVC(kernel='poly', degree=3, C=1).fit(X_train, y_train)\n",
    "    poly_pred = poly.predict(X_test)\n",
    "    rbf_pred = rbf.predict(X_test)\n",
    "    poly_accuracy = accuracy_score(y_test, poly_pred)\n",
    "    poly_f1 = f1_score(y_test, poly_pred, average='weighted')\n",
    "    print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))\n",
    "    print('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1*100))\n",
    "    rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
    "    rbf_f1 = f1_score(y_test, rbf_pred, average='weighted')\n",
    "    print('Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\n",
    "    print('F1 (RBF Kernel): ', \"%.2f\" % (rbf_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "742fdf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Polynomial Kernel):  55.10\n",
      "F1 (Polynomial Kernel):  50.04\n",
      "Accuracy (RBF Kernel):  26.53\n",
      "F1 (RBF Kernel):  11.13\n"
     ]
    }
   ],
   "source": [
    "svm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e8abd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
