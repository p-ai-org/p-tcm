{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb0a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46c43bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/data_processed.csv', index_col=0)\n",
    "# df = pd.read_csv('./data/data_processed_normalized.csv', index_col=0)\n",
    "df = pd.read_csv('./data/raw_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b168f7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Food Name', 'Water (g)', 'Energy (kal)', 'Protein (g)', 'lipid (g)',\n",
       "       'Carbohydrate (g)', 'Fiber (g)', 'Ash (g)', 'Ca (mg)', 'Fe (mg)',\n",
       "       'Mg (mg)', 'P (mg)', 'K (mg)', 'Na (mg)', 'Zn (mg)', 'Se (µg)',\n",
       "       'Cu (mg)', 'Mn (mg)', 'Vc (mg)', 'Thiamin (mg)', 'Riboflavin (mg)',\n",
       "       'Niacin (mg)', 'B6 (mg)', 'Folate,DFE (µg)', 'B12 (µg)', 'Va,RAE (µg)',\n",
       "       'Ve (mg)', 'saturated (g)', 'monounsaturated (g)',\n",
       "       'polyunsaturated (g)', 'trans (g)', 'Cholesterol (mg)', 'Caffeine (mg)',\n",
       "       'phenolics (mg)', 'pH', 'Plain Occurences', 'Cool Occurences',\n",
       "       'Warm Occurences', 'Cold Occurences', 'Heavy Cold Occurences',\n",
       "       'Heavy Warm Occurences', 'Hot Occurences', 'Heavy Hot Occurences',\n",
       "       '% Plain', '% Cool', '% Warm', '% Cold', '% Heavy Cold', '% Heavy Warm',\n",
       "       '% Hot', '% Heavy Hot', 'hot_cold_scale', 'Plain', 'Cold', 'Hot',\n",
       "       'Mode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc5eb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food Name</th>\n",
       "      <th>Water (g)</th>\n",
       "      <th>Energy (kal)</th>\n",
       "      <th>Protein (g)</th>\n",
       "      <th>lipid (g)</th>\n",
       "      <th>Carbohydrate (g)</th>\n",
       "      <th>Fiber (g)</th>\n",
       "      <th>Ash (g)</th>\n",
       "      <th>Ca (mg)</th>\n",
       "      <th>Fe (mg)</th>\n",
       "      <th>...</th>\n",
       "      <th>% Cold</th>\n",
       "      <th>% Heavy Cold</th>\n",
       "      <th>% Heavy Warm</th>\n",
       "      <th>% Hot</th>\n",
       "      <th>% Heavy Hot</th>\n",
       "      <th>hot_cold_scale</th>\n",
       "      <th>Plain</th>\n",
       "      <th>Cold</th>\n",
       "      <th>Hot</th>\n",
       "      <th>Mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfalfa</td>\n",
       "      <td>0.903084</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.092251</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.029565</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.093645</td>\n",
       "      <td>0.028747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dolichos sinensis</td>\n",
       "      <td>0.902082</td>\n",
       "      <td>0.020362</td>\n",
       "      <td>0.040590</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.074421</td>\n",
       "      <td>0.080827</td>\n",
       "      <td>0.007014</td>\n",
       "      <td>0.051839</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hazelnuts</td>\n",
       "      <td>0.053164</td>\n",
       "      <td>0.710407</td>\n",
       "      <td>0.275830</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>0.170252</td>\n",
       "      <td>0.182331</td>\n",
       "      <td>0.041082</td>\n",
       "      <td>0.095318</td>\n",
       "      <td>0.048255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beans, kidney</td>\n",
       "      <td>0.117641</td>\n",
       "      <td>0.376697</td>\n",
       "      <td>0.435055</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.611785</td>\n",
       "      <td>0.468045</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peanuts,</td>\n",
       "      <td>0.065078</td>\n",
       "      <td>0.641403</td>\n",
       "      <td>0.476015</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.164441</td>\n",
       "      <td>0.159774</td>\n",
       "      <td>0.032064</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.047023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Plain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Food Name  Water (g)  Energy (kal)  Protein (g)  lipid (g)  \\\n",
       "0            Alfalfa   0.903084      0.036199     0.092251     0.0070   \n",
       "1  dolichos sinensis   0.902082      0.020362     0.040590     0.0030   \n",
       "2          hazelnuts   0.053164      0.710407     0.275830     0.6075   \n",
       "3      Beans, kidney   0.117641      0.376697     0.435055     0.0083   \n",
       "4           Peanuts,   0.065078      0.641403     0.476015     0.4924   \n",
       "\n",
       "   Carbohydrate (g)  Fiber (g)   Ash (g)   Ca (mg)   Fe (mg)  ...  % Cold  \\\n",
       "0          0.029565   0.035714  0.012024  0.093645  0.028747  ...     0.0   \n",
       "1          0.074421   0.080827  0.007014  0.051839  0.008214  ...     0.0   \n",
       "2          0.170252   0.182331  0.041082  0.095318  0.048255  ...     0.0   \n",
       "3          0.611785   0.468045  0.009018  0.119565  0.084189  ...     0.0   \n",
       "4          0.164441   0.159774  0.032064  0.076923  0.047023  ...     0.0   \n",
       "\n",
       "   % Heavy Cold  % Heavy Warm  % Hot  % Heavy Hot  hot_cold_scale  Plain  \\\n",
       "0           0.0           0.0    0.0          0.0             0.5      3   \n",
       "1           0.0           0.0    0.0          0.0             0.5      3   \n",
       "2           0.0           0.0    0.0          0.0             0.5      3   \n",
       "3           0.0           0.0    0.0          0.0             0.5      3   \n",
       "4           0.0           0.0    0.0          0.0             0.5      3   \n",
       "\n",
       "   Cold  Hot   Mode  \n",
       "0     0    0  Plain  \n",
       "1     0    0  Plain  \n",
       "2     0    0  Plain  \n",
       "3     0    0  Plain  \n",
       "4     0    0  Plain  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683aa79",
   "metadata": {},
   "source": [
    "TO DO label encoder, temp solution\n",
    "\n",
    "df['hot_cold_scale'] = df['hot_cold_scale'] * 10\n",
    "df['hot_cold_scale'] = df['hot_cold_scale'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a840f9c",
   "metadata": {},
   "source": [
    "### Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2bb0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    df.loc[\"Water (g)\": \"pH\"] = (df.loc[\"Water (g)\": \"pH\"]-df.loc[\"Water (g)\": \"pH\"].mean())/df.loc[\"Water (g)\": \"pH\"].std()\n",
    "    \n",
    "    name = df.iloc[:, 0:1]\n",
    "    inputs = df.loc[:, 'Water (g)':'pH'].astype(float)\n",
    "    outputs = df.loc[:, 'pH':].drop(columns='pH')\n",
    "\n",
    "    # normalized_inputs = (inputs-inputs.mean())/inputs.std()\n",
    "    normalized_inputs=(inputs-inputs.min())/(inputs.max()-inputs.min())\n",
    "    \n",
    "    df = pd.concat([name, normalized_inputs, outputs], axis=1)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccea62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occurrences(df):\n",
    "    df[\"% Plain\"] = df[\"Plain Occurences\"]/(df[\"Plain Occurences\"] + df[\"Cool Occurences\"] + df[\"Warm Occurences\"] + df[\"Cold Occurences\"] + df[\"Heavy Cold Occurences\"] + df[\"Heavy Warm Occurences\"] + df[\"Hot Occurences\"] + df[\"Heavy Hot Occurences\"])\n",
    "\n",
    "    df[\"% Cool\"] = df[\"Cool Occurences\"]/(df[\"Plain Occurences\"] + df[\"Cool Occurences\"] + df[\"Warm Occurences\"] + df[\"Cold Occurences\"] + df[\"Heavy Cold Occurences\"] + df[\"Heavy Warm Occurences\"] + df[\"Hot Occurences\"] + df[\"Heavy Hot Occurences\"])\n",
    "\n",
    "    df[\"% Warm\"] = df[\"Warm Occurences\"]/(df[\"Plain Occurences\"] + df[\"Cool Occurences\"] + df[\"Warm Occurences\"] + df[\"Cold Occurences\"] + df[\"Heavy Cold Occurences\"] + df[\"Heavy Warm Occurences\"] + df[\"Hot Occurences\"] + df[\"Heavy Hot Occurences\"])\n",
    "\n",
    "    df[\"% Cold\"] = df[\"Cold Occurences\"]/(df[\"Plain Occurences\"] + df[\"Cool Occurences\"] + df[\"Warm Occurences\"] + df[\"Cold Occurences\"] + df[\"Heavy Cold Occurences\"] + df[\"Heavy Warm Occurences\"] + df[\"Hot Occurences\"] + df[\"Heavy Hot Occurences\"])\n",
    "\n",
    "    df[\"% Heavy Cold\"] = df[\"Heavy Cold Occurences\"]/(df[\"Plain Occurences\"] + df[\"Cool Occurences\"] + df[\"Warm Occurences\"] + df[\"Cold Occurences\"] + df[\"Heavy Cold Occurences\"] + df[\"Heavy Warm Occurences\"] + df[\"Hot Occurences\"] + df[\"Heavy Hot Occurences\"])\n",
    "\n",
    "    df[\"% Heavy Warm\"] = df[\"Heavy Warm Occurences\"]/(df[\"Plain Occurences\"] + df[\"Cool Occurences\"] + df[\"Warm Occurences\"] + df[\"Cold Occurences\"] + df[\"Heavy Cold Occurences\"] + df[\"Heavy Warm Occurences\"] + df[\"Hot Occurences\"] + df[\"Heavy Hot Occurences\"])\n",
    "\n",
    "    df[\"% Hot\"] = df[\"Hot Occurences\"]/(df[\"Plain Occurences\"] + df[\"Cool Occurences\"] + df[\"Warm Occurences\"] + df[\"Cold Occurences\"] + df[\"Heavy Cold Occurences\"] + df[\"Heavy Warm Occurences\"] + df[\"Hot Occurences\"] + df[\"Heavy Hot Occurences\"])\n",
    "\n",
    "    df[\"% Heavy Hot\"] = df[\"Heavy Hot Occurences\"]/(df[\"Plain Occurences\"] + df[\"Cool Occurences\"] + df[\"Warm Occurences\"] + df[\"Cold Occurences\"] + df[\"Heavy Cold Occurences\"] + df[\"Heavy Warm Occurences\"] + df[\"Hot Occurences\"] + df[\"Heavy Hot Occurences\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "781c8325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_scale(df):\n",
    "#     df[\"hot_cold_scale\"] = (df[\"% Plain\"] * (3.0/7.0)) + (df[\"% Cool\"] * (2.0/7.0)) + (df[\"% Warm\"] * (4.0/7.0)) + (df[\"% Cold\"] * (1.0/7.0)) + (df[\"% Heavy Cold\"] * (0.0/7.0)) + (df[\"% Heavy Warm\"] * (5.0/7.0)) + (df[\"% Hot\"] * (6.0/7.0)) + (df[\"% Heavy Hot\"] * (7.0/7.0))\n",
    "    df[\"hot_cold_scale\"] = (df[\"% Plain\"] * (3.0/6.0)) + (df[\"% Cool\"] * (2.0/6.0)) + (df[\"% Warm\"] * (4.0/6.0)) + (df[\"% Cold\"] * (1.0/6.0)) + (df[\"% Heavy Cold\"] * (0.0/6.0)) + (df[\"% Heavy Warm\"] * (4.5/6.0)) + (df[\"% Hot\"] * (5.0/6.0)) + (df[\"% Heavy Hot\"] * (6.0/6.0))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6445712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(df):\n",
    "    df['Plain'] = df['Plain Occurences'].astype(int)\n",
    "    df['Cold'] = df['Cool Occurences'].astype(int) + df['Cold Occurences'].astype(int) + df['Heavy Cold Occurences'].astype(int)\n",
    "    df['Hot'] = df['Warm Occurences'].astype(int) + df['Heavy Warm Occurences'].astype(int) + df['Hot Occurences'].astype(int) + df['Heavy Hot Occurences'].astype(int)\n",
    "    newDf = pd.DataFrame(df.loc[:, ['Plain', 'Cold', 'Hot']].idxmax(axis=1))\n",
    "    df[\"Mode\"] = newDf[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b115737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanValuesRid(df):\n",
    "    not_too_many_null_cols = df.columns[df.isnull().mean() < 0.3]\n",
    "    df = df[not_too_many_null_cols]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04b82169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_imputation(df):\n",
    "    ii_imp = IterativeImputer(estimator=ExtraTreesRegressor(), max_iter=10, random_state=1121218)\n",
    "\n",
    "    name = df.iloc[:, 0:1]\n",
    "    inputs = df.loc[:, 'Water (g)':'pH']\n",
    "    outputs = df.loc[:, 'pH':].drop(columns='pH')\n",
    "    \n",
    "    inputs = ii_imp.fit_transform(inputs)\n",
    "    new_inputs = pd.DataFrame(inputs, columns = not_too_many_null_cols[1:35]) \n",
    "    \n",
    "    return pd.concat([name, new_inputs, outputs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "302bed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df):\n",
    "    # reading word labels\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "    # encode word labels in column\n",
    "    df['hot_cold_scale'] = label_encoder.fit_transform(df['hot_cold_scale'])\n",
    "\n",
    "    df['hot_cold_scale'].unique()\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a7bbb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df):\n",
    "    df = normalize(df)\n",
    "    \n",
    "    df = nanValuesRid(df)\n",
    "    \n",
    "    df = iterative_imputation(df)\n",
    "    \n",
    "    df = label_encoder(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5dfef386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 241 entries, 0 to 240\n",
      "Data columns (total 60 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             241 non-null    object \n",
      " 1   Water (g)              241 non-null    float64\n",
      " 2   Energy (kal)           241 non-null    float64\n",
      " 3   Protein (g)            239 non-null    float64\n",
      " 4   lipid (g)              239 non-null    float64\n",
      " 5   Carbohydrate (g)       240 non-null    float64\n",
      " 6   Fiber (g)              221 non-null    float64\n",
      " 7   Sugars (g)             168 non-null    float64\n",
      " 8   Ash (g)                227 non-null    float64\n",
      " 9   Ca (mg)                237 non-null    float64\n",
      " 10  Fe (mg)                238 non-null    float64\n",
      " 11  Mg (mg)                236 non-null    float64\n",
      " 12  P (mg)                 238 non-null    float64\n",
      " 13  K (mg)                 237 non-null    float64\n",
      " 14  Na (mg)                238 non-null    float64\n",
      " 15  Zn (mg)                239 non-null    float64\n",
      " 16  Se (µg)                190 non-null    float64\n",
      " 17  Cu (mg)                200 non-null    float64\n",
      " 18  Mn (mg)                195 non-null    float64\n",
      " 19  I (µg)                 74 non-null     float64\n",
      " 20  Vc (mg)                210 non-null    float64\n",
      " 21  Thiamin (mg)           234 non-null    float64\n",
      " 22  Riboflavin (mg)        236 non-null    float64\n",
      " 23  Niacin (mg)            232 non-null    float64\n",
      " 24  B6 (mg)                187 non-null    float64\n",
      " 25  Folate,DFE (µg)        184 non-null    float64\n",
      " 26  B12 (µg)               185 non-null    float64\n",
      " 27  Va,RAE (µg)            218 non-null    float64\n",
      " 28  Ve (mg)                196 non-null    float64\n",
      " 29  Vd (IU)                150 non-null    float64\n",
      " 30  Vk (µg)                142 non-null    float64\n",
      " 31  saturated (g)          202 non-null    float64\n",
      " 32  monounsaturated (g)    202 non-null    float64\n",
      " 33  polyunsaturated (g)    198 non-null    float64\n",
      " 34  trans (g)              170 non-null    float64\n",
      " 35  Cholesterol (mg)       193 non-null    float64\n",
      " 36  Caffeine (mg)          223 non-null    float64\n",
      " 37  phenolics (mg)         215 non-null    float64\n",
      " 38  pH                     178 non-null    float64\n",
      " 39  Plain Occurences       241 non-null    int64  \n",
      " 40  Cool Occurences        241 non-null    int64  \n",
      " 41  Warm Occurences        241 non-null    int64  \n",
      " 42  Cold Occurences        241 non-null    int64  \n",
      " 43  Heavy Cold Occurences  241 non-null    int64  \n",
      " 44  Heavy Warm Occurences  241 non-null    int64  \n",
      " 45  Hot Occurences         241 non-null    int64  \n",
      " 46  Heavy Hot Occurences   241 non-null    int64  \n",
      " 47  % Plain                241 non-null    float64\n",
      " 48  % Cool                 241 non-null    float64\n",
      " 49  % Warm                 241 non-null    float64\n",
      " 50  % Cold                 241 non-null    float64\n",
      " 51  % Heavy Cold           241 non-null    float64\n",
      " 52  % Heavy Warm           241 non-null    float64\n",
      " 53  % Hot                  241 non-null    float64\n",
      " 54  % Heavy Hot            241 non-null    float64\n",
      " 55  Plain                  241 non-null    int64  \n",
      " 56  Cold                   241 non-null    int64  \n",
      " 57  Hot                    241 non-null    int64  \n",
      " 58  Mode                   241 non-null    object \n",
      " 59  hot_cold_scale         241 non-null    float64\n",
      "dtypes: float64(47), int64(11), object(2)\n",
      "memory usage: 113.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = occurrences(df)\n",
    "df = linear_scale(df)\n",
    "df = mode(df)\n",
    "cols = list(df.columns.values)\n",
    "cols.pop(cols.index('hot_cold_scale'))\n",
    "df = df[cols+['hot_cold_scale']]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e49dbc7",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "235e522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(df, y_col_name):\n",
    "    \"\"\"\n",
    "    Apply sample logistic regression model to dataframe\n",
    "\n",
    "    df : (dataframe)\n",
    "    x : (compounds column as int)\n",
    "    y : (classification column as int)\n",
    "    \"\"\"\n",
    "    # values of each column\n",
    "    x = df.iloc[:, 1:] # df.iloc[2:, 1:39]??\n",
    "    y = df[y_col_name][:]\n",
    "\n",
    "    # split data into training and test set\n",
    "    # 75 training, 25 testing\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    train = data_process(pd.concat([xtrain, ytrain]))\n",
    "    xtrain = trian.iloc[:, 1:39]\n",
    "    ytrain = train[y_col_name][:]\n",
    "    \n",
    "    test = data_process(pd.concat([xtest, ytest], axis=1))\n",
    "    xtest = test.iloc[:, 1:39]\n",
    "    ytest = test[y_col_name][:]\n",
    "\n",
    "\n",
    "    # standardize and scale data\n",
    "    scaler = StandardScaler()\n",
    "    xtrain = scaler.fit_transform(xtrain)\n",
    "    xtest = scaler.transform(xtest)\n",
    "\n",
    "    # modeling + analysis\n",
    "    model = LogisticRegression(random_state=0)\n",
    "    model.fit(xtrain, ytrain.ravel())\n",
    "    y_pred = model.predict(xtest)\n",
    "\n",
    "    # confusion matrix of test size\n",
    "    conf_m = confusion_matrix(ytest, y_pred)\n",
    "    print(\"Confusion Matrix : \", conf_m)\n",
    "\n",
    "    # accuracy score of test size\n",
    "    print (\"Accuracy : \", accuracy_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f2d9bf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Water (g)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Water (g)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vm/xcq0807952vg0zwpp4yx698w0000gn/T/ipykernel_63991/1691645542.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hot_cold_scale\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/vm/xcq0807952vg0zwpp4yx698w0000gn/T/ipykernel_63991/1201370152.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(df, y_col_name)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mxtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m39\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/vm/xcq0807952vg0zwpp4yx698w0000gn/T/ipykernel_63991/173094187.py\u001b[0m in \u001b[0;36mdata_process\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moccurrences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/vm/xcq0807952vg0zwpp4yx698w0000gn/T/ipykernel_63991/3579958802.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Water (g)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pH\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Water (g)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pH\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Water (g)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pH\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Water (g)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pH\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Water (g)'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'pH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_indexer\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   5683\u001b[0m         \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5684\u001b[0m         \"\"\"\n\u001b[0;32m-> 5685\u001b[0;31m         \u001b[0mstart_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5687\u001b[0m         \u001b[0;31m# return a slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_locs\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   5885\u001b[0m         \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5886\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5887\u001b[0;31m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_slice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5889\u001b[0m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   5805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5806\u001b[0m                 \u001b[0;31m# raise the original KeyError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5807\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   5799\u001b[0m         \u001b[0;31m# we need to look up the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5800\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5801\u001b[0;31m             \u001b[0mslc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5802\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5803\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/analysis-gniU7RWb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Water (g)'"
     ]
    }
   ],
   "source": [
    "logistic_regression(df, \"hot_cold_scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc966dc",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(df, y_col_name):\n",
    "    x = df.iloc[:, 1:39]\n",
    "    y = df[y_col_name][:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    print (\"Accuracy : \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77dfca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(df, \"hot_cold_scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec43447",
   "metadata": {},
   "source": [
    "more processing for following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0330ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_mode(row):\n",
    "    if row['Mode'] == 'Plain':\n",
    "        return 0\n",
    "    elif row['Mode'] == 'Cold':\n",
    "        return 1\n",
    "    elif row['Mode'] == 'Hot':\n",
    "        return 2\n",
    "    \n",
    "df['mode_code'] = df.apply (lambda row: label_mode(row), axis=1)\n",
    "df = df.drop(columns='Food Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a86d51",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495829a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(df):\n",
    "    X = df.drop([\"Plain Occurences\", \"Cool Occurences\", \"Warm Occurences\", \"Cold Occurences\", \"Heavy Cold Occurences\", \"Heavy Warm Occurences\",\"Hot Occurences\", \"Heavy Hot Occurences\", \"mode_code\", \"Mode\"], axis = 1)\n",
    "    Y = df[\"mode_code\"].astype('int')\n",
    "    factor = pd.factorize(df['Mode'])\n",
    "    df.Mode = factor[0]\n",
    "    definitions = factor[1]\n",
    "    print(definitions)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 21)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    reversefactor = dict(zip(range(3),definitions))\n",
    "    y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "    y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "    print(pd.crosstab(y_test, y_pred, rownames=['Actual Temp'], colnames=['Predicted Temp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65be827",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_forest(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd6ae67",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(df):\n",
    "    X = df.drop([\"Plain Occurences\", \"Cool Occurences\", \"Warm Occurences\", \"Cold Occurences\", \"Heavy Cold Occurences\", \"Heavy Warm Occurences\",\"Hot Occurences\", \"Heavy Hot Occurences\", \"mode_code\", \"Mode\"], axis = 1)\n",
    "    y = df[\"mode_code\"]\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.80, test_size=0.20, random_state=101)\n",
    "    rbf = SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train, y_train)\n",
    "    poly = SVC(kernel='poly', degree=3, C=1).fit(X_train, y_train)\n",
    "    poly_pred = poly.predict(X_test)\n",
    "    rbf_pred = rbf.predict(X_test)\n",
    "    poly_accuracy = accuracy_score(y_test, poly_pred)\n",
    "    poly_f1 = f1_score(y_test, poly_pred, average='weighted')\n",
    "    print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))\n",
    "    print('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1*100))\n",
    "    rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
    "    rbf_f1 = f1_score(y_test, rbf_pred, average='weighted')\n",
    "    print('Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\n",
    "    print('F1 (RBF Kernel): ', \"%.2f\" % (rbf_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742fdf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e8abd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
